{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['h.0.attn.c_attn.bias', 'h.0.attn.c_attn.kernel', 'h.0.attn.c_proj.bias', 'h.0.attn.c_proj.kernel', 'h.0.ln_1.bias', 'h.0.ln_1.scale', 'h.0.ln_2.bias', 'h.0.ln_2.scale', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_fc.kernel', 'h.0.mlp.c_proj.bias', 'h.0.mlp.c_proj.kernel', 'h.1.attn.c_attn.bias', 'h.1.attn.c_attn.kernel', 'h.1.attn.c_proj.bias', 'h.1.attn.c_proj.kernel', 'h.1.ln_1.bias', 'h.1.ln_1.scale', 'h.1.ln_2.bias', 'h.1.ln_2.scale', 'h.1.mlp.c_fc.bias', 'h.1.mlp.c_fc.kernel', 'h.1.mlp.c_proj.bias', 'h.1.mlp.c_proj.kernel', 'h.10.attn.c_attn.bias', 'h.10.attn.c_attn.kernel', 'h.10.attn.c_proj.bias', 'h.10.attn.c_proj.kernel', 'h.10.ln_1.bias', 'h.10.ln_1.scale', 'h.10.ln_2.bias', 'h.10.ln_2.scale', 'h.10.mlp.c_fc.bias', 'h.10.mlp.c_fc.kernel', 'h.10.mlp.c_proj.bias', 'h.10.mlp.c_proj.kernel', 'h.11.attn.c_attn.bias', 'h.11.attn.c_attn.kernel', 'h.11.attn.c_proj.bias', 'h.11.attn.c_proj.kernel', 'h.11.ln_1.bias', 'h.11.ln_1.scale', 'h.11.ln_2.bias', 'h.11.ln_2.scale', 'h.11.mlp.c_fc.bias', 'h.11.mlp.c_fc.kernel', 'h.11.mlp.c_proj.bias', 'h.11.mlp.c_proj.kernel', 'h.2.attn.c_attn.bias', 'h.2.attn.c_attn.kernel', 'h.2.attn.c_proj.bias', 'h.2.attn.c_proj.kernel', 'h.2.ln_1.bias', 'h.2.ln_1.scale', 'h.2.ln_2.bias', 'h.2.ln_2.scale', 'h.2.mlp.c_fc.bias', 'h.2.mlp.c_fc.kernel', 'h.2.mlp.c_proj.bias', 'h.2.mlp.c_proj.kernel', 'h.3.attn.c_attn.bias', 'h.3.attn.c_attn.kernel', 'h.3.attn.c_proj.bias', 'h.3.attn.c_proj.kernel', 'h.3.ln_1.bias', 'h.3.ln_1.scale', 'h.3.ln_2.bias', 'h.3.ln_2.scale', 'h.3.mlp.c_fc.bias', 'h.3.mlp.c_fc.kernel', 'h.3.mlp.c_proj.bias', 'h.3.mlp.c_proj.kernel', 'h.4.attn.c_attn.bias', 'h.4.attn.c_attn.kernel', 'h.4.attn.c_proj.bias', 'h.4.attn.c_proj.kernel', 'h.4.ln_1.bias', 'h.4.ln_1.scale', 'h.4.ln_2.bias', 'h.4.ln_2.scale', 'h.4.mlp.c_fc.bias', 'h.4.mlp.c_fc.kernel', 'h.4.mlp.c_proj.bias', 'h.4.mlp.c_proj.kernel', 'h.5.attn.c_attn.bias', 'h.5.attn.c_attn.kernel', 'h.5.attn.c_proj.bias', 'h.5.attn.c_proj.kernel', 'h.5.ln_1.bias', 'h.5.ln_1.scale', 'h.5.ln_2.bias', 'h.5.ln_2.scale', 'h.5.mlp.c_fc.bias', 'h.5.mlp.c_fc.kernel', 'h.5.mlp.c_proj.bias', 'h.5.mlp.c_proj.kernel', 'h.6.attn.c_attn.bias', 'h.6.attn.c_attn.kernel', 'h.6.attn.c_proj.bias', 'h.6.attn.c_proj.kernel', 'h.6.ln_1.bias', 'h.6.ln_1.scale', 'h.6.ln_2.bias', 'h.6.ln_2.scale', 'h.6.mlp.c_fc.bias', 'h.6.mlp.c_fc.kernel', 'h.6.mlp.c_proj.bias', 'h.6.mlp.c_proj.kernel', 'h.7.attn.c_attn.bias', 'h.7.attn.c_attn.kernel', 'h.7.attn.c_proj.bias', 'h.7.attn.c_proj.kernel', 'h.7.ln_1.bias', 'h.7.ln_1.scale', 'h.7.ln_2.bias', 'h.7.ln_2.scale', 'h.7.mlp.c_fc.bias', 'h.7.mlp.c_fc.kernel', 'h.7.mlp.c_proj.bias', 'h.7.mlp.c_proj.kernel', 'h.8.attn.c_attn.bias', 'h.8.attn.c_attn.kernel', 'h.8.attn.c_proj.bias', 'h.8.attn.c_proj.kernel', 'h.8.ln_1.bias', 'h.8.ln_1.scale', 'h.8.ln_2.bias', 'h.8.ln_2.scale', 'h.8.mlp.c_fc.bias', 'h.8.mlp.c_fc.kernel', 'h.8.mlp.c_proj.bias', 'h.8.mlp.c_proj.kernel', 'h.9.attn.c_attn.bias', 'h.9.attn.c_attn.kernel', 'h.9.attn.c_proj.bias', 'h.9.attn.c_proj.kernel', 'h.9.ln_1.bias', 'h.9.ln_1.scale', 'h.9.ln_2.bias', 'h.9.ln_2.scale', 'h.9.mlp.c_fc.bias', 'h.9.mlp.c_fc.kernel', 'h.9.mlp.c_proj.bias', 'h.9.mlp.c_proj.kernel', 'ln_f.bias', 'ln_f.scale', 'wpe.embedding', 'wte.embedding'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import FlaxGPT2LMHeadModel\n",
    "model = FlaxGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "from flax.core import unfreeze\n",
    "from flax.traverse_util import flatten_dict\n",
    "\n",
    "params = unfreeze(model.params['transformer'])\n",
    "params = flatten_dict(params, sep='.')\n",
    "\n",
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.0.attn.c_attn.bias Shape: (2304,)\n",
      "h.0.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.0.attn.c_proj.bias Shape: (768,)\n",
      "h.0.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.0.ln_1.bias Shape: (768,)\n",
      "h.0.ln_1.scale Shape: (768,)\n",
      "h.0.ln_2.bias Shape: (768,)\n",
      "h.0.ln_2.scale Shape: (768,)\n",
      "h.0.mlp.c_fc.bias Shape: (3072,)\n",
      "h.0.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.0.mlp.c_proj.bias Shape: (768,)\n",
      "h.0.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.1.attn.c_attn.bias Shape: (2304,)\n",
      "h.1.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.1.attn.c_proj.bias Shape: (768,)\n",
      "h.1.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.1.ln_1.bias Shape: (768,)\n",
      "h.1.ln_1.scale Shape: (768,)\n",
      "h.1.ln_2.bias Shape: (768,)\n",
      "h.1.ln_2.scale Shape: (768,)\n",
      "h.1.mlp.c_fc.bias Shape: (3072,)\n",
      "h.1.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.1.mlp.c_proj.bias Shape: (768,)\n",
      "h.1.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.10.attn.c_attn.bias Shape: (2304,)\n",
      "h.10.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.10.attn.c_proj.bias Shape: (768,)\n",
      "h.10.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.10.ln_1.bias Shape: (768,)\n",
      "h.10.ln_1.scale Shape: (768,)\n",
      "h.10.ln_2.bias Shape: (768,)\n",
      "h.10.ln_2.scale Shape: (768,)\n",
      "h.10.mlp.c_fc.bias Shape: (3072,)\n",
      "h.10.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.10.mlp.c_proj.bias Shape: (768,)\n",
      "h.10.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.11.attn.c_attn.bias Shape: (2304,)\n",
      "h.11.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.11.attn.c_proj.bias Shape: (768,)\n",
      "h.11.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.11.ln_1.bias Shape: (768,)\n",
      "h.11.ln_1.scale Shape: (768,)\n",
      "h.11.ln_2.bias Shape: (768,)\n",
      "h.11.ln_2.scale Shape: (768,)\n",
      "h.11.mlp.c_fc.bias Shape: (3072,)\n",
      "h.11.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.11.mlp.c_proj.bias Shape: (768,)\n",
      "h.11.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.2.attn.c_attn.bias Shape: (2304,)\n",
      "h.2.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.2.attn.c_proj.bias Shape: (768,)\n",
      "h.2.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.2.ln_1.bias Shape: (768,)\n",
      "h.2.ln_1.scale Shape: (768,)\n",
      "h.2.ln_2.bias Shape: (768,)\n",
      "h.2.ln_2.scale Shape: (768,)\n",
      "h.2.mlp.c_fc.bias Shape: (3072,)\n",
      "h.2.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.2.mlp.c_proj.bias Shape: (768,)\n",
      "h.2.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.3.attn.c_attn.bias Shape: (2304,)\n",
      "h.3.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.3.attn.c_proj.bias Shape: (768,)\n",
      "h.3.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.3.ln_1.bias Shape: (768,)\n",
      "h.3.ln_1.scale Shape: (768,)\n",
      "h.3.ln_2.bias Shape: (768,)\n",
      "h.3.ln_2.scale Shape: (768,)\n",
      "h.3.mlp.c_fc.bias Shape: (3072,)\n",
      "h.3.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.3.mlp.c_proj.bias Shape: (768,)\n",
      "h.3.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.4.attn.c_attn.bias Shape: (2304,)\n",
      "h.4.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.4.attn.c_proj.bias Shape: (768,)\n",
      "h.4.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.4.ln_1.bias Shape: (768,)\n",
      "h.4.ln_1.scale Shape: (768,)\n",
      "h.4.ln_2.bias Shape: (768,)\n",
      "h.4.ln_2.scale Shape: (768,)\n",
      "h.4.mlp.c_fc.bias Shape: (3072,)\n",
      "h.4.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.4.mlp.c_proj.bias Shape: (768,)\n",
      "h.4.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.5.attn.c_attn.bias Shape: (2304,)\n",
      "h.5.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.5.attn.c_proj.bias Shape: (768,)\n",
      "h.5.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.5.ln_1.bias Shape: (768,)\n",
      "h.5.ln_1.scale Shape: (768,)\n",
      "h.5.ln_2.bias Shape: (768,)\n",
      "h.5.ln_2.scale Shape: (768,)\n",
      "h.5.mlp.c_fc.bias Shape: (3072,)\n",
      "h.5.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.5.mlp.c_proj.bias Shape: (768,)\n",
      "h.5.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.6.attn.c_attn.bias Shape: (2304,)\n",
      "h.6.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.6.attn.c_proj.bias Shape: (768,)\n",
      "h.6.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.6.ln_1.bias Shape: (768,)\n",
      "h.6.ln_1.scale Shape: (768,)\n",
      "h.6.ln_2.bias Shape: (768,)\n",
      "h.6.ln_2.scale Shape: (768,)\n",
      "h.6.mlp.c_fc.bias Shape: (3072,)\n",
      "h.6.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.6.mlp.c_proj.bias Shape: (768,)\n",
      "h.6.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.7.attn.c_attn.bias Shape: (2304,)\n",
      "h.7.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.7.attn.c_proj.bias Shape: (768,)\n",
      "h.7.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.7.ln_1.bias Shape: (768,)\n",
      "h.7.ln_1.scale Shape: (768,)\n",
      "h.7.ln_2.bias Shape: (768,)\n",
      "h.7.ln_2.scale Shape: (768,)\n",
      "h.7.mlp.c_fc.bias Shape: (3072,)\n",
      "h.7.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.7.mlp.c_proj.bias Shape: (768,)\n",
      "h.7.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.8.attn.c_attn.bias Shape: (2304,)\n",
      "h.8.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.8.attn.c_proj.bias Shape: (768,)\n",
      "h.8.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.8.ln_1.bias Shape: (768,)\n",
      "h.8.ln_1.scale Shape: (768,)\n",
      "h.8.ln_2.bias Shape: (768,)\n",
      "h.8.ln_2.scale Shape: (768,)\n",
      "h.8.mlp.c_fc.bias Shape: (3072,)\n",
      "h.8.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.8.mlp.c_proj.bias Shape: (768,)\n",
      "h.8.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "h.9.attn.c_attn.bias Shape: (2304,)\n",
      "h.9.attn.c_attn.kernel Shape: (2304, 768)\n",
      "h.9.attn.c_proj.bias Shape: (768,)\n",
      "h.9.attn.c_proj.kernel Shape: (768, 768)\n",
      "h.9.ln_1.bias Shape: (768,)\n",
      "h.9.ln_1.scale Shape: (768,)\n",
      "h.9.ln_2.bias Shape: (768,)\n",
      "h.9.ln_2.scale Shape: (768,)\n",
      "h.9.mlp.c_fc.bias Shape: (3072,)\n",
      "h.9.mlp.c_fc.kernel Shape: (3072, 768)\n",
      "h.9.mlp.c_proj.bias Shape: (768,)\n",
      "h.9.mlp.c_proj.kernel Shape: (768, 3072)\n",
      "ln_f.bias Shape: (768,)\n",
      "ln_f.scale Shape: (768,)\n",
      "wpe.embedding Shape: (1024, 768)\n",
      "wte.embedding Shape: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    print(f\"{param} Shape: {params[param].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['h.0.attn.c_attn', 'h.0.attn.c_proj', 'h.0.ln_1', 'h.0.ln_2', 'h.0.mlp.c_fc', 'h.0.mlp.c_proj', 'h.1.attn.c_attn', 'h.1.attn.c_proj', 'h.1.ln_1', 'h.1.ln_2', 'h.1.mlp.c_fc', 'h.1.mlp.c_proj', 'h.2.attn.c_attn', 'h.2.attn.c_proj', 'h.2.ln_1', 'h.2.ln_2', 'h.2.mlp.c_fc', 'h.2.mlp.c_proj', 'h.3.attn.c_attn', 'h.3.attn.c_proj', 'h.3.ln_1', 'h.3.ln_2', 'h.3.mlp.c_fc', 'h.3.mlp.c_proj', 'h.4.attn.c_attn', 'h.4.attn.c_proj', 'h.4.ln_1', 'h.4.ln_2', 'h.4.mlp.c_fc', 'h.4.mlp.c_proj', 'h.5.attn.c_attn', 'h.5.attn.c_proj', 'h.5.ln_1', 'h.5.ln_2', 'h.5.mlp.c_fc', 'h.5.mlp.c_proj', 'h.6.attn.c_attn', 'h.6.attn.c_proj', 'h.6.ln_1', 'h.6.ln_2', 'h.6.mlp.c_fc', 'h.6.mlp.c_proj', 'h.7.attn.c_attn', 'h.7.attn.c_proj', 'h.7.ln_1', 'h.7.ln_2', 'h.7.mlp.c_fc', 'h.7.mlp.c_proj', 'h.8.attn.c_attn', 'h.8.attn.c_proj', 'h.8.ln_1', 'h.8.ln_2', 'h.8.mlp.c_fc', 'h.8.mlp.c_proj', 'h.9.attn.c_attn', 'h.9.attn.c_proj', 'h.9.ln_1', 'h.9.ln_2', 'h.9.mlp.c_fc', 'h.9.mlp.c_proj', 'h.10.attn.c_attn', 'h.10.attn.c_proj', 'h.10.ln_1', 'h.10.ln_2', 'h.10.mlp.c_fc', 'h.10.mlp.c_proj', 'h.11.attn.c_attn', 'h.11.attn.c_proj', 'h.11.ln_1', 'h.11.ln_2', 'h.11.mlp.c_fc', 'h.11.mlp.c_proj', 'lm_head', 'ln_f', 'wpe', 'wte'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax_gpt2 import GPT, GPTConfig\n",
    "import flax.nnx as nn\n",
    "\n",
    "model = GPT(GPTConfig(), nn.Rngs(0))\n",
    "\n",
    "jax_modules_dict = {}\n",
    "for module_pair in model.iter_modules():\n",
    "    if type(module_pair[1]).__name__  in ['Block', 'CausalSelfAttention', 'GPT', 'MLP']:\n",
    "        continue\n",
    "    module_path = '.'.join([str(x) for x in module_pair[0]])\n",
    "    module = module_pair[1]\n",
    "    jax_modules_dict[module_path] = module\n",
    "\n",
    "jax_modules_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(768, 50257)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['wte.embedding'].shape\n",
    "jax_modules_dict['lm_head'].kernel.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2304,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax_modules_dict['h.0.attn.c_attn'].bias.value.dtype\n",
    "params['h.0.attn.c_attn.bias'].dtype\n",
    "\n",
    "jax_modules_dict['h.0.attn.c_attn'].bias.value.shape\n",
    "params['h.0.attn.c_attn.bias'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
